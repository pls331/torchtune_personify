# Config for running the EvalRecipe in eval_mteb.py to evaluate embedding model on MTEB
#
# TODO(pls331): support tune download
#
# To launch, run the following command:
#    tune run dev/eval_mteb --config llama3_2_embedding\eval_mteb

# Model arguments
model:
  _component_: torchtune.models.llama3_2_embedding.llama3_2_1b_text_encoder

# Transform arguments
tokenizer:
  _component_: torchtune.models.llama3.llama3_tokenizer
  path: /tmp/Llama-3.2-1B-Instruct/original/tokenizer.model
  max_seq_len: 2048

# Checkpointer
checkpointer:
  _component_: torchtune.training.FullModelHFCheckpointer
  checkpoint_dir: /tmp/Llama-3.2-1B-Instruct/
  checkpoint_files: [
    # Orignal checkpoint files
    model.safetensors 
    # TODO: ms-marco 1 epoch in a new file
  ]
  recipe_checkpoint: null
  output_dir: /tmp/Llama-3.2-1B-Instruct/
  model_type: LLAMA3_2

# Device
device: cuda
dtype: bf16
seed: 1234
log_level: INFO

# Eval arguments
eval:
  output_dir: /tmp/Llama-3.2-1B-Instruct/eval_output
  mteb:
    batch_size: 256
    task_selectors: 
      - task_types: ["Retrieval"]
      - categories: []
      - languages: []


